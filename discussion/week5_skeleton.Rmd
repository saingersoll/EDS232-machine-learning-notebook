```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(here) #easy file paths
library(tidyverse) #data wrangling
library(tidymodels) #modeling

set.seed(42) #set random seed
```

### Data Introduction

This data was acquired form FishBase (Froese and Pauley 2000) using the rfishbase package (Boettiger et al., 2012; see data_acquisition.R for data retrieval). 

The data set includes the following variables:

* `species`: the scientific name of fish 
* `genus`: the scientific genus of fish
* `common_name`: common name used for fish
* `body_shape`**: shape of fish body (elongated, fusiform/normal, eel-like, short and/or deep, other)**
* `habitat`**: area of the ocean that fish typically resides in **
* `depth_range_shallow`**: minimum depth fish is found**
* `depth_range_deep`**: maximum depth fish is found**
* `vulnerability`**: metric for how at risk a fish is to over fishing based on other life history and ecological traits**
* `length`**: total length, fork length, or standard length of fish**
* `trophic_level`**: trophic level that the fish occupies based on position in food web **
* `food_troph`: trophic level that fish's food source occupies
* `food`**: type of food source fish consumes **
* `family`: the scientific family of fish

*Bold variables are included in the models. A full copy of the codebook is included in the data/raw folder*

#### Habitat Types 

This project attempts to predict 8 different habitat types. These habitats are described below to note differences.

1. pelagic: living within several regions of the pelagic zone, through both shallower pelagic-oceanic and deeper bathypelagic
2. pelagic-neritic: relating to upper layers of the ocean on the continental shelf. Waters here are not as deep as the pelagic zone
3. reef-associated: living in association with a coral reef. This habitat is the most diverse, offering an array of food types and shelters
4. demersal: relating to living on or near the ocean floor, whether in the pelagic-neritic, pelagic, or bathypelagic zones   
5. benthopelagic: relating specifically to the ocean floor in the pelagic zone, but not at the deepest depths
6. bathydemersal: relating to the ocean floor at depths greater than 200 meters
7. pelagic-oceanic: relating specifically to the upper layers of the open ocean. Food is scarce
8. bathypelagic: relating to deeper layers of the open ocean at the continental slope. Limited sunlight reaches this zone

While there is some possible overlap in these categories, they are kept separate as specifically defined in FishBase. Data has already been pre-processed for you. 

#### Data Cleaning

Today, we are going to use all habitats!

```{r}

fish_clean = read_csv(here("discussion", "data", "fish_clean.csv")) %>% 
  mutate(habitat = as.factor(habitat))

```

### Modeling

Today, we will look at preforming K-nearest neighbors on this data set. We will continue to come back to this data set as we learn more models in this section.

##### Habitat Counts

```{r}
ggplot(fish_clean, aes(habitat)) + #order by count
  geom_bar() + #get counts
  theme_bw() + #bw theme
  labs(x = "Habitat",
       y = "Count") + #change labels
  theme(axis.text.x = element_text(angle = 30, 
                                   hjust = 1)) #rotate x axis labels
```

#### Training and Testing Data Creation

Here, we will use functions from the `rsample` package within `TidyModels`

```{r}
data_split = initial_split(fish_clean, prop = .8, strata = habitat) #split data stratified by survived

train = training(data_split)#get training data
test = testing(data_split) #get testing data
```

In order to find the best model for the data, I will be using cross validation to tune the parameters for each of the models. This is accomplished by splitting the data into 5 folds for 10-fold cross validation.

```{r}
# set up cv folds
cv_folds <- vfold_cv(train,
                     v = 5)
```

#### Recipe Creation

After splitting my data, the first step is to create a recipe indicating the formula for the model and any pre-processing steps I want to preform on my data. Here we will use the `recipes` package.

I will be predicting habitat based on trophic level, length, minimum depth, maximum depth, vulnerability, body shape, and food source type. We will be normalizing all numeric predictors

```{r}
fish_recipe = recipe(habitat ~ shape_impute + food_impute + shallow_impute + deep_impute + vulnerability + length_impute + trophic_level_impute,
                     data = train) %>%
  # create model recipe. create this for nominal predictors so they may be made numeric
  step_dummy(all_nominal_predictors()) %>% 
  # create dummy variables from all factors. normalizing numerics
  step_normalize(all_numeric_predictors())
  
```

#### Model 3: K-nearest neighbors

```{r}
?nearest_neighbor
```

I will be using the kknn engine (Schliep and Hechenbichler 2016) for this model and tuning the number of neighbors (k) to determine the best value.

This works best for distinct clusters because there are patterns of cluster aggregation. Unsupervized algorithim, not always 100% accurate. Assigns data points to clusters, typically has issues due to class imbalances. Random forest and tree based algorithims avoid this

```{r}
knn_model <- nearest_neighbor(
  mode = "classification",
  engine = "kknn",
  neighbors = tune()
)

knn_model
```
Bundling recipe in a workflow will automatically prep and bake our data and transform it while fitting.

```{r}
knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(fish_recipe)
  
knn_workflow
```

##### Parameter Tuning

After creating my workflow for my KNN model, I will be using `tune_grid()` to get 10 possible values for k and using cross validation to fit the model to the folds in order to determine the best value for number of neighbors. Make sure you set eval = FALSE when knitting

```{r, eval = FALSE}

# knn cv tune randomly sample 5 knn and test accuracy

# TAKES FOREVER TO RUN so we loaded Allie's data in next chunk


#knn_cv_tune <- knn_workflow %>% 
 # tune_grid(resamples = cv_folds,
    #        grid = 5)    

```

#### stored data frames in a rda (holds weird objects)
using `save()` including the object name of my desired information to be stored.
```{r, include=FALSE}
load(file = here::here("discussion","data", "knn_tune.rda"))
```

#### Visualize the metrics from file
```{r}
collect_metrics(knn_cv_tune)
```
Accuracy is very bias due to class imbalance.
Want to choose somewhere that has the highest ROC, variance is more importance (sensitivity and specificity). Assess both the false negative and positive.
```{r}
autoplot(knn_cv_tune) +
  theme_bw()
```

#### Finalize workflow

Using quartiles as a range of measuring se by interpetting an appropriate amount of error a model may output.

```{r}
# show us the best model
show_best(knn_cv_tune,
          metric = 'roc_auc')

# now using the workflow, establish a model with the best model with roc_auc metric
knn_final <- finalize_workflow(knn_workflow,
                               select_best(knn_cv_tune,
                                           metric = 'roc_auc'))
knn_final
```

#### Model Fitting

*these all take a few seconds*

```{r, eval = FALSE}
train_fit = fit(knn_final, train) #fit the KNN model to the training set

train_fit
```
Training
```{r}
# Predicts only the class value highest probability 
train_predict = predict(object = train_fit, new_data = train) %>% #predict the training set
  bind_cols(train) #bind training set column to prediction

# predicts the individual prediction for each factor of value in observations
train_predict2 = predict(object = train_fit, new_data = train, type = "prob") %>% #predict the training set
  bind_cols(train) #bind training set column to prediction
```

Testing
```{r}

test_predict = predict(train_fit, test) %>% #get prediction probabilities for test 
  bind_cols(test) %>%  #bind to testing column
  mutate(habitat = as.factor(habitat))

test_predict2 = predict(train_fit, test, type = "prob") %>% #get testing prediction
  bind_cols(test) %>%  #bind to testing column
  mutate(habitat = as.factor(habitat))
```

#### Model Metrics and Evaluation

```{r}
# 86 % accuracy
accuracy(train_predict, truth = habitat, estimate = .pred_class) #get training accuracy

# sensitivity true positive rate: false negatives (WANT HIGH) 
sensitivity(train_predict, truth = habitat, estimate = .pred_class)
# specificity True negative rate: false positives (WANT LOW)
specificity(train_predict, truth = habitat, estimate = .pred_class)

test_roc_auc <- roc_curve(train_predict2,
                          habitat,
                          .pred_bathydemersal,
                          .pred_bathypelagic,
                          .pred_benthopelagic,
                          .pred_pelagic,
                          '.pred_pelagic-neritic',
                          '.pred_pelagic-oceanic',
                          '.pred_reef-associated'
                          )
```

```{r}
test_predict = predict(train_fit, test) %>% #get prediction probabilities for test 
  bind_cols(test) %>%  #bind to testing column
  mutate(habitat = as.factor(habitat))

test_predict2 = predict(train_fit, test, type = "prob") %>% #get testing prediction
  bind_cols(test) %>%  #bind to testing column
  mutate(habitat = as.factor(habitat))
```

```{r}
accuracy(test_predict, truth = habitat, estimate = .pred_class) #get accuracy of testing prediction

sensitivity(test_predict, truth = habitat, estimate = .pred_class)
specificity(test_predict, truth = habitat, estimate = .pred_class)

#get testing ROC AUC
```

#### Visualizations

```{r}
test_predict %>% 
  conf_mat(truth = habitat,
           estimate = .pred_class) %>% 
  autoplot(type = 'heatmap') +
  theme_bw() +
  theme(
    
    axis.text.x = element_text(
      angle = 30,
      hjust = 1
    )
  )
```

```{r}

```


