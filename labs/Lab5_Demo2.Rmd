---
title: "Lab5_Demo2"
author: "Sofia Ingersoll"
date: "2023-02-15"
output: html_document
---
Libraries 
```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(vip) #variable importance
library(here)

set.seed(99)
```
## R
```{r}
# genre data set
kaggle_dat <- read_csv(here("data","genres_v2.csv"))

#kaggle_playlist <- read_csv(here("data","playlist.csv"))

unique(kaggle_dat$genre)
table(kaggle_dat$genre)

#Removing uninformative columns and selecting trap and Hiphop as the two genres here and making case consistent

genre_dat <- kaggle_dat %>%
  select(-c(type, uri, track_href, analysis_url, `Unnamed: 0`, title, tempo, id, song_name)) %>%
  filter(genre == "Hiphop"| genre == "Rap") %>%
  mutate(genre = str_replace(genre, "Hiphop", "hiphop")) %>%
  mutate(genre = str_replace(genre, "Rap", "rap")) %>%
  mutate(genre = as.factor(genre))

head(genre_dat)
```

```{r}
# split the data
genre_split <- initial_split(genre_dat)

# traing data
genre_train <- training(genre_split)

# testing data
genre_test <- testing(genre_split)
```
Predict genre using other variables
```{r recipe}
# Preprocess the data
genre_rec <- recipe(genre ~ ., data = genre_train) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  step_normalize(all_numeric())
  
```

Set up a decision tree specification. Note: the cost_complexity parameter is a pruning penalty parameter that controls how much we penalize the number of terminal nodes in the tree.  It's conceptually similar to lambda from regularized regression.

This model does not get used, simply an example of how you can autofill
```{r tree_specification}
tree_spec_fixed <- decision_tree(
  cost_complexity = 0.1,
  tree_depth = 4,
  min_n = 11
) %>% 
  set_engine('rpart', times = 50) %>% 
  set_mode('classification')
```

But, as usual, we don't want just any old values for our hyperparameters, we want optimal values.

It is best practice to tune first before selecting (auto-fixing) model values. 
```{r}
#new spec, tell the model that we are tuning hyperparams
tree_spec_tune <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) %>% 
  set_engine('rpart') %>% 
  set_mode('classification')

# info about the possible range of this hyperparameter valuea
# 5 x 5 x 5 grid of the parameters for cross validation
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)

# view the cross validation observations
tree_grid
```
Time to tune the tuning model 

The autofill would be directly fit without tuning. Tuning is required for tune to set the model parameters.
```{r workflow_tree}
wf_tree_tune <- workflow() %>% 
  add_recipe(genre_rec) %>% 
  add_model(tree_spec_tune)
```

Cross Validation
```{r resampling}
#set up k-fold cv. This can be used for all the algorithms
genre_cv <- genre_train %>% 
  vfold_cv(v = 10)

# visualize our 10 cv folds
genre_cv
```

```{r}
doParallel::registerDoParallel() #build trees in parallel
#200s
system.time(
  tree_rs <- tune_grid(
    wf_tree_tune,
    resamples = genre_cv,
    grid = tree_grid,
    metrics = metric_set(accuracy)
  )
)

tree_rs
```
Use autoplot() to examine how different parameter configurations relate to accuracy 

Below, tree depth 4 demonstrates the highest level of accuracy across the various nodes
```{r}
# visualize our model
autoplot(tree_rs) +
  theme_bw()
```
Show me in order what are the most optimal set of parameters to use on my model
```{r select_hyperparam}
# includes accurary info
show_best(tree_rs, n = 3)

# no accuracy info
select_best(tree_rs)
```

We can finalize the model specification where we have replaced the tune functions with optimized values.

```{r final_tree_spec}
final_tree <- finalize_workflow(wf_tree_tune,
                                select_best(tree_rs))

final_tree
```

This model has not been fit yet though.

```{r final_tree_fit}
#similar functions here.
final_tree_fit <- fit(final_tree,
                      data = genre_train) 

# last_fit() fits on the training data but then also evaluates on test data
# this combines fit and predict
final_tree_result <- last_fit(final_tree,
                              genre_split)

# data predictions
final_tree_result$.predictions
# how well the model accuracy split the data
final_tree_result$.metrics
```

#Visualize variable importance

How important is this variable for determing prediction
```{r tree_vip}
final_tree_fit %>% 
  vip(geom = 'col',
      aesthetics = list(fill = 'midnightblue'),
      alpha = 0.8) +
  scale_y_continuous(expand = c(0,0)) 



predict_data <- as.data.frame(final_tree_result$.predictions) %>% 
  bind_cols(genre_test)

ggplot() +
  geom_boxplot(data = predict_data,
               aes(.pred_class,
                   duration_ms))

ggplot() +
  geom_boxplot(data = predict_data,
               aes(.pred_class,
                   acousticness))
```


